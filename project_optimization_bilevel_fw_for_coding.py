# -*- coding: utf-8 -*-
"""Project Optimization -  Bilevel FW for coding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xkV-a52mvan7Pnd3MfT-GO86_YpbctPA

Bilevel FW for coding
Study the theory of the attached papers
Implement the bilevel optimization algorithm [Algorithm 1, Jiang et
al] for online dictionary learning, comparing with the baseline FW method
test the algorithms following the lines of Section 5.3 in paper[Jiang et al]

# Imports and Setup
"""

#libraries
import numpy as np
import torch
import torch.random
import matplotlib.pyplot as plt
import copy
import scipy
import random
from scipy.optimize import fsolve
import math

"""#Functions"""

"""
OBJECTIVE FUNCTION: in linear programming problems, the objective function refers to the real-valued function whose value has to be
either maximized or minimized, according to the constraints that are defined on the specified linear programming problem over a set of
possible solutions. It is essentially a mathematical expression that describes the problem’s objective and can be made as large or small as possible.

TENSOR: algebraic object that describes a multilinear relationship between sets of algebraic objects related to a vector space.
Tensors may map between different objects such as vectors, scalars, and even other tensors.
"""

def obj_function(A, D, X):  #problem 5
  s = 0
  for i in range(A.shape[0]):                                   #for every row
    s = s + torch.norm(A[i,:] - torch.matmul(D, X[:,i]), 2)     #norm second of the summation a[i] -DX[i]
    #A[i,:] is the ith row
    #torch.matmul is the multiplication, matrix product of two tensors.
  return s/(2*A.shape[0])                                       #divided by 2N

#LMO = LINEAR OPT ORACLE
def LMO_2(gradient):
  min_n = np.finfo(float).eps                               #the minimum quantity between two float number, to avoid the division by 0
  out = -gradient/(min_n + torch.norm(gradient, dim=0))     #Normalize every row of the gradient by his norm
  return out  #descent direction

def LMO_1(gradient, eps):
  max_idx = torch.argmax(torch.abs(gradient), axis=0)        #for every row, take the argmax
  out = torch.zeros(gradient.shape)
  for j in range(gradient.shape[1]):
    out[max_idx[j], j] = -eps * torch.sign(gradient[max_idx[j], j]) #eps/-eps based on the sign of the argmax
  return out  #descent direction

def gradD(D,X,A):
  return (D@X - A.T)@X.T

def gradX(D,X,A):
  return D.T@(D@X-A.T)

#dictionary learning
def frank_wolfe(max_iter, A, D, X, flag, epsx, stop_condition): #flag = which tensor I have to compute {0 = D, 1 = X & D}
  D0 = D
  X0 = X
  loss_hist = []        #to append the loss and then create an histogram

  for k in range(max_iter):
    f0 = obj_function(A, D, X)            #compute the object function
    loss_hist.append(f0.item())           #append the loss

    #setting the stepsize
    if flag == 0:
      stepsize = 0.01
    else:
      stepsize = 0.1/(k+2)

    if flag == 0: #D
      gradient = gradD(D,X,A)                           #compute the gradient
      descent_direction = LMO_2(gradient)               #compute the descent direction

      frank_wolfe_gap  = torch.trace(gradient.T @ (D-descent_direction))    #torch.trace compute the trace of a matrix, the sum of diagonal elements

      D = (1-stepsize) * D + stepsize * descent_direction                   #update D

      if frank_wolfe_gap < stop_condition:
        print("The frank wolf algorith break for the gap at iteration", k, "with frank wolfe gap of value", frank_wolfe_gap.item())
        return loss_hist, D

    else:         #D and X
      #X
      gradient_x = gradX(D,X,A)                                   #compute the gradient
      descent_direction_X = LMO_1(gradient_x, epsx)               #compute the descent direction

      #D
      gradient_d = gradD(D,X,A)                                   #compute the gradient
      descent_direction_D = LMO_2(gradient_d)                     #compute the descent direction

      frank_wolfe_gap_D  = torch.trace(gradient_d.T @ (D-descent_direction_D))    #torch.trace compute the trace of a matrix, the sum of diagonal elements
      frank_wolfe_gap_X  = torch.trace(gradient_x.T @ (X-descent_direction_X))    #torch.trace compute the trace of a matrix, the sum of diagonal elements
      frank_wolfe_gap = frank_wolfe_gap_D + frank_wolfe_gap_X

      D = (1-stepsize) * D + stepsize * descent_direction_D       #update D
      X = (1-stepsize) * X + (stepsize) * descent_direction_X     #update X

      if frank_wolfe_gap < stop_condition:                        #Check termination condition, frank wolfe gap
        print("The frank wolf algorith break for the gap at iteration", k, "with frank wolfe gap of value", frank_wolfe_gap.item())
        return loss_hist, X, D

  print("Get maximum numers of iterations")

  if flag == 0:
    return loss_hist, D
  else:
    return loss_hist, X, D

def D_lambda(lam, grad_f_D, grad_g_D):                      #find the value of D lambda
  lam = lam.item()                                          #take the value of lambda
  min_n = np.finfo(float).eps                               #the minimum quantity between two float number, to avoid the division by 0
  return -(grad_f_D + lam*grad_g_D)/(min_n + torch.norm(grad_f_D + lam*grad_g_D, dim=0))  #final equation normalized by the norm for every row

def eqn_lambda(lam, grad_f_D, grad_g_D, delta):                                 #find the value of the final equation
  return torch.trace(grad_g_D.T @ D_lambda(lam, grad_f_D, grad_g_D)) - delta    #torch.trace compute the trace of a matrix, the sum of diagonal elements

"""
1: Input: Target accuracy ϵf , ϵg > 0, stepsizes {γk}k
2: Initialization: Set x0 ∈ Z s.t. g(x0) − g∗ ≤ ϵg/2

3: for k = 0, . . . ,K − 1 do
  4: Compute sk ← argmins∈Xk
  ⟨∇f(xk), s⟩
  Xk≜{s ∈ Z : ⟨∇g(xk), s − xk⟩≤g(x0)−g(xk)}

    5: if ⟨∇f(xk), xk − sk⟩ ≤ ϵf and
      ⟨∇g(xk), xk − sk⟩ ≤ ϵg/2 then
      6: Return xk and STOP
    7: else
      8: xk+1 ← (1 − γk)xk + γksk
    9: end if

10: end for
"""

def bilevel_optimization(Ai, A, D0, X0, X_old, epsx, epsilon_f, max_iter): #epsilon_f > 0,  0 <= stepsize <= 1
  #d0 = frank_wolfe(100, A, D, X, 0, 1, 0.001)
  #x0 = frank_wolfe(100, A, D, X, 1, 1, 0.001)  #choose x0 ∈ Z s.t. g(x0) - g∗ ≤ ϵg/2
  Dk = D0                            #for the update
  Xk = X0                            #for the update
  loss_f = []                        #to append the loss and then create an histogram
  loss_g = []                        #to append the loss and then create an histogram
  l0 = obj_function(A, Dk, X_old)    #compute the object function

  for k in range(max_iter):
    stepsize = 0.3/math.sqrt(k+1)
    f = obj_function(Ai, Dk , Xk)    #compute the object function
    grad_f_D = gradD(Dk,Xk,Ai)       #compute the gradient
    grad_f_X = gradX(Dk,Xk,Ai)       #compute the gradient

    g = obj_function(A, Dk, X_old)    #compute the object function
    grad_g_D = gradD(Dk, X_old, A)    #compute the gradient

    loss_f.append(f)                  #append the loss
    loss_g.append(g)                  #append the loss

    delta = l0 - g + torch.trace(grad_g_D.T @  Dk)          #torch.trace compute the trace of a matrix, the sum of diagonal elements
    lam = scipy.optimize.fsolve(eqn_lambda, 0.001, xtol = 0.000001, args = (grad_f_D, grad_g_D, delta))     #find lambda for the last equatiion
    descent_direction_D = D_lambda(lam, grad_f_D, grad_g_D)                                                 #compute the descent direction

    descent_direction_X = LMO_1(grad_f_X, epsx)             #compute descent direction for X

    frank_wolfe_gap_D  = torch.trace(grad_f_D.T @ (Dk-descent_direction_D))  #torch.trace compute the trace of a matrix, the sum of diagonal elements
    frank_wolfe_gap_X  = torch.trace(grad_f_X.T @ (Xk-descent_direction_X))  #torch.trace compute the trace of a matrix, the sum of diagonal elements
    frank_wolfe_gap = frank_wolfe_gap_D + frank_wolfe_gap_X

    if frank_wolfe_gap <= epsilon_f:     #Check termination condition, frank wolfe gap
      print("The frank wolf algorith break for the gap at iteration", k, "with frank wolfe gap of value", frank_wolfe_gap)
      return Dk, loss_f, loss_g

    Dk = (1 - stepsize)*Dk + stepsize*descent_direction_D     #update D
    Xk = (1 - stepsize)*Xk + stepsize*descent_direction_X     #update X
  return Dk, loss_f, loss_g

def euclidean_projection(tensor, p=2):
  for i in range(tensor.shape[1]):                                #for every tensor's column
    if torch.norm(tensor[:,i], p=p) > 0:                          #if the second norm is greater than zero
      tensor[:,i] = tensor[:,i]/torch.norm(tensor[:,i], p=p)      #the tensor's column is normzlized by the second norm

  return tensor

"""# Execution

## initialization and dataset generation
"""

#We first generate the true dictionary ˜D∗ ∈ R25×50 consisting of 50 basis vectors in R25, each of which has its entries
#drawn from a standard Gaussian distribution and is normalized to have unit ℓ2-norm

true_D = torch.rand(size=(25, 50))
true_D = true_D/torch.norm(true_D, dim=0, p=2)

#We further construct the two dictionaries D∗ and D′∗ consisting of 40 and 20 basis vectors in ˜D∗,
#respectively (and hence they share 10 bases in common)

D_old = true_D[:, :40]
D_new = true_D[:, 30:]

#sparse  matrices
k_spar = 5  # number of nonzeros in each coefficient vector

#X_old
mask = np.zeros((40, 250))
for i in range(mask.shape[1]):
  sampled_indices = np.random.choice(4 * mask.shape[0] // 5, k_spar, replace=False)   #5 non zero entry
  mask[sampled_indices, i] = (0.8 * np.random.rand(k_spar) + 0.2) * (2 * np.random.randint(0, 2, k_spar) - 1)
mask = mask.astype(np.float32)
X_old = torch.tensor(mask)  # true coefficient matrix for the old dataset


#X_new
mask = np.zeros((20, 200))
for i in range(mask.shape[1]):
  sampled_indices = np.random.choice(4 * mask.shape[0] // 5, k_spar, replace=False)
  mask[sampled_indices, i] = (0.8 * np.random.rand(k_spar) + 0.2) * (2 * np.random.randint(0, 2, k_spar) - 1)
mask = mask.astype(np.float32)
X_new = torch.tensor(mask)  # true coefficient matrix for the old dataset

#noise vectors
noise_vector_old = torch.rand(size=(D_old @ X_old).shape) * 0.01 #0.01 = noise level
noise_vector_new = torch.rand(size=(D_new @ X_new).shape) * 0.01 #0.01 = noise level

#generate the dataset
A = ((D_old @ X_old) + noise_vector_old).T
Ai = ((D_new @ X_new) + noise_vector_new).T

#for problem 5 and 6, which is the limit in which the norm of xi < sigma
constraint_gamma = 3

D = torch.rand(D_old.shape)
X = torch.zeros(X_old.shape)

#normalization on the rows to encourage sparsity
D = D/torch.norm(D, dim=0)

loss, X, D = frank_wolfe(1000, A, D, X, 1, constraint_gamma, 3)

plt.plot(loss)

plt.xlabel('Iterations')
plt.ylabel('Loss score')

# displaying the title
plt.title("Loss trend for the 1000 frank wolfe iterations over X")

plt.show()

loss_d, D = frank_wolfe(1000, A, D, X, 0, constraint_gamma, 0.1)

plt.plot(loss + loss_d)

plt.xlabel('Iterations')
plt.ylabel('Loss score')

# displaying the title
plt.title("Loss trend for the 2000 frank wolfe iterations over D")

plt.show()

X_old = torch.cat([X, torch.zeros((10, X.shape[1]))], axis=0)   #X + 10 zero rows

D_old = torch.cat([D, torch.zeros((D.shape[0], 10))], axis=1)   #X + 10 zero columns

X_new = torch.zeros(size=(50, 200))

D, loss_f, loss_g = bilevel_optimization(Ai, A, D_old, X_new, X_old, 3, 10, max_iter = 1000)

plt.plot(loss_f)

plt.xlabel('Iterations')
plt.ylabel('Loss score')

# displaying the title
plt.title("Loss trend for the 1000 CG-Bio iterations for the upper-level problem")

plt.show()

plt.plot(torch.round(torch.tensor(loss_g),decimals = 1))

plt.xlabel('Iterations')
plt.ylabel('Loss score')

# displaying the title
plt.title("Loss trend for the 1000 CG-Bio iterations for the lower-level problem")

plt.show()